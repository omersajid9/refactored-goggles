{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LSTM/RNN HIDDEN STATE SHAPE EXPLANATION\n",
      "============================================================\n",
      "X INPUT SHAPE: torch.Size([16, 4])\n",
      "  ‚îî‚îÄ Breakdown: [batch_size=16, sequence_length=4]\n",
      "\n",
      "EMBED OUTPUT SHAPE: torch.Size([16, 4, 126])\n",
      "  ‚îî‚îÄ Breakdown: [batch_size=16, sequence_length=4, embedding_dim=126]\n",
      "\n",
      "MODEL OUTPUT SHAPE: torch.Size([16, 4, 256])\n",
      "  ‚îî‚îÄ Breakdown: [batch_size=16, sequence_length=4, hidden_size=256]\n",
      "\n",
      "MODEL HIDDEN SHAPE: torch.Size([2, 16, 256])\n",
      "  ‚îî‚îÄ Breakdown: [num_layers=2, batch_size=16, hidden_size=256]\n",
      "\n",
      "============================================================\n",
      "DETAILED HIDDEN STATE EXPLANATION\n",
      "============================================================\n",
      "\n",
      "üîç HIDDEN STATE DIMENSIONS BREAKDOWN:\n",
      "\n",
      "Your hidden shape: torch.Size([2, 16, 256])\n",
      "                           ‚Üë   ‚Üë    ‚Üë\n",
      "                           ‚îÇ   ‚îÇ    ‚îî‚îÄ HIDDEN_SIZE (256)\n",
      "                           ‚îÇ   ‚îî‚îÄ BATCH_SIZE (16)  \n",
      "                           ‚îî‚îÄ NUM_LAYERS (2)\n",
      "\n",
      "üìö WHAT EACH DIMENSION MEANS:\n",
      "\n",
      "1Ô∏è‚É£  NUM_LAYERS = 2\n",
      "   ‚Ä¢ You have a 2-layer RNN/LSTM\n",
      "   ‚Ä¢ Hidden state contains the final hidden vector from EACH layer\n",
      "   ‚Ä¢ Layer 0: First RNN layer's final hidden state\n",
      "   ‚Ä¢ Layer 1: Second RNN layer's final hidden state\n",
      "\n",
      "2Ô∏è‚É£  BATCH_SIZE = 16\n",
      "   ‚Ä¢ You're processing 16 sequences simultaneously\n",
      "   ‚Ä¢ Each sequence has its own hidden state\n",
      "   ‚Ä¢ Enables parallel processing\n",
      "\n",
      "3Ô∏è‚É£  HIDDEN_SIZE = 256\n",
      "   ‚Ä¢ Each hidden state vector has 256 dimensions\n",
      "   ‚Ä¢ This is the internal memory capacity of each RNN cell\n",
      "   ‚Ä¢ Stores the \"compressed\" information from the sequence\n",
      "\n",
      "üîÑ HIDDEN STATE EVOLUTION:\n",
      "\n",
      "At each timestep, the RNN updates its hidden state:\n",
      "\n",
      "TIMESTEP-BY-TIMESTEP HIDDEN STATE EVOLUTION:\n",
      "--------------------------------------------------\n",
      "Initial hidden state: torch.Size([2, 16, 256])\n",
      "  ‚îî‚îÄ All zeros: [num_layers=2, batch_size=16, hidden_size=256]\n",
      "\n",
      "Timestep 1:\n",
      "  Input shape: torch.Size([16, 1, 126])\n",
      "  Output shape: torch.Size([16, 1, 256])\n",
      "  Hidden shape: torch.Size([2, 16, 256])\n",
      "  ‚îî‚îÄ Hidden state updated for all 16 sequences\n",
      "\n",
      "Timestep 2:\n",
      "  Input shape: torch.Size([16, 1, 126])\n",
      "  Output shape: torch.Size([16, 1, 256])\n",
      "  Hidden shape: torch.Size([2, 16, 256])\n",
      "  ‚îî‚îÄ Hidden state updated for all 16 sequences\n",
      "\n",
      "Timestep 3:\n",
      "  Input shape: torch.Size([16, 1, 126])\n",
      "  Output shape: torch.Size([16, 1, 256])\n",
      "  Hidden shape: torch.Size([2, 16, 256])\n",
      "  ‚îî‚îÄ Hidden state updated for all 16 sequences\n",
      "\n",
      "Timestep 4:\n",
      "  Input shape: torch.Size([16, 1, 126])\n",
      "  Output shape: torch.Size([16, 1, 256])\n",
      "  Hidden shape: torch.Size([2, 16, 256])\n",
      "  ‚îî‚îÄ Hidden state updated for all 16 sequences\n",
      "\n",
      "üéØ FINAL HIDDEN STATE:\n",
      "Shape: torch.Size([2, 16, 256])\n",
      "Contains the 'final memory' of each sequence after processing all 4 timesteps\n",
      "\n",
      "============================================================\n",
      "COMPARISON: OUTPUT vs HIDDEN\n",
      "============================================================\n",
      "\n",
      "üìä OUTPUT TENSOR: torch.Size([16, 4, 256])\n",
      "   ‚Ä¢ Contains RNN output at EVERY timestep\n",
      "   ‚Ä¢ Shape: [batch_size, sequence_length, hidden_size]\n",
      "   ‚Ä¢ Use for: Many-to-many tasks (your case)\n",
      "\n",
      "üß† HIDDEN TENSOR: torch.Size([2, 16, 256])\n",
      "   ‚Ä¢ Contains FINAL hidden state from each layer\n",
      "   ‚Ä¢ Shape: [num_layers, batch_size, hidden_size]  \n",
      "   ‚Ä¢ Use for: Many-to-one tasks, or as input to next sequence\n",
      "\n",
      "üîç ACCESSING HIDDEN STATES:\n",
      "\n",
      "# Access final hidden state from last layer:\n",
      "hidden[-1].shape = torch.Size([16, 256])\n",
      "\n",
      "# Access hidden state from first layer:\n",
      "hidden[0].shape = torch.Size([16, 256])\n",
      "\n",
      "# Access hidden state for specific batch item:\n",
      "hidden[:, 0, :].shape = torch.Size([2, 256])\n",
      "\n",
      "============================================================\n",
      "LSTM vs RNN HIDDEN STATES\n",
      "============================================================\n",
      "\n",
      "üîÑ RNN HIDDEN STATE:\n",
      "   ‚Ä¢ Returns: hidden\n",
      "   ‚Ä¢ Shape: torch.Size([2, 16, 256])\n",
      "   ‚Ä¢ Contains: Final hidden state from each layer\n",
      "\n",
      "üß† LSTM HIDDEN STATE:\n",
      "   ‚Ä¢ Returns: (hidden, cell)\n",
      "   ‚Ä¢ Hidden shape: torch.Size([2, 16, 256])\n",
      "   ‚Ä¢ Cell shape: torch.Size([2, 16, 256])\n",
      "   ‚Ä¢ Contains: Both hidden state AND cell state (LSTM's memory)\n",
      "\n",
      "üí° KEY INSIGHT:\n",
      "   LSTM returns TWO states because it has:\n",
      "   1. Hidden state (h) - what it outputs\n",
      "   2. Cell state (c) - internal memory\n",
      "\n",
      "\n",
      "============================================================\n",
      "PRACTICAL USAGE EXAMPLES\n",
      "============================================================\n",
      "\n",
      "üéØ WHEN TO USE HIDDEN STATE:\n",
      "\n",
      "1Ô∏è‚É£  MANY-TO-ONE TASKS:\n",
      "   classifier = nn.Linear(hidden_size, num_classes)\n",
      "   prediction = classifier(hidden[-1])  # Use final layer's hidden state\n",
      "\n",
      "2Ô∏è‚É£  SEQUENCE CONTINUATION:\n",
      "   # Use final hidden state as initial state for next sequence\n",
      "   next_output, next_hidden = rnn(next_input, hidden)\n",
      "\n",
      "3Ô∏è‚É£  ENCODER-DECODER:\n",
      "   # Hidden state from encoder becomes initial state for decoder\n",
      "   decoder_output, _ = decoder_rnn(decoder_input, encoder_hidden)\n",
      "\n",
      "4Ô∏è‚É£  ATTENTION MECHANISMS:\n",
      "   # Use hidden states from all layers for attention computation\n",
      "   attention_weights = attention_layer(hidden)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Let's recreate your scenario and explain the shapes\n",
    "print(\"=\"*60)\n",
    "print(\"LSTM/RNN HIDDEN STATE SHAPE EXPLANATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Your model setup (based on the shapes you provided)\n",
    "vocab_size = 1000  # example\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "batch_size = 16\n",
    "sequence_length = 4\n",
    "embedding_dim = 126\n",
    "\n",
    "# Create model components\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "rnn = nn.RNN(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "# Your actual data\n",
    "x = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
    "print(f\"X INPUT SHAPE: {x.shape}\")\n",
    "print(f\"  ‚îî‚îÄ Breakdown: [batch_size={batch_size}, sequence_length={sequence_length}]\")\n",
    "\n",
    "# Embedding layer\n",
    "embedded = embedding(x)\n",
    "print(f\"\\nEMBED OUTPUT SHAPE: {embedded.shape}\")\n",
    "print(f\"  ‚îî‚îÄ Breakdown: [batch_size={batch_size}, sequence_length={sequence_length}, embedding_dim={embedding_dim}]\")\n",
    "\n",
    "# RNN layer\n",
    "output, hidden = rnn(embedded)\n",
    "print(f\"\\nMODEL OUTPUT SHAPE: {output.shape}\")\n",
    "print(f\"  ‚îî‚îÄ Breakdown: [batch_size={batch_size}, sequence_length={sequence_length}, hidden_size={hidden_size}]\")\n",
    "\n",
    "print(f\"\\nMODEL HIDDEN SHAPE: {hidden.shape}\")\n",
    "print(f\"  ‚îî‚îÄ Breakdown: [num_layers={num_layers}, batch_size={batch_size}, hidden_size={hidden_size}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED HIDDEN STATE EXPLANATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üîç HIDDEN STATE DIMENSIONS BREAKDOWN:\n",
    "\n",
    "Your hidden shape: torch.Size([2, 16, 256])\n",
    "                           ‚Üë   ‚Üë    ‚Üë\n",
    "                           ‚îÇ   ‚îÇ    ‚îî‚îÄ HIDDEN_SIZE (256)\n",
    "                           ‚îÇ   ‚îî‚îÄ BATCH_SIZE (16)  \n",
    "                           ‚îî‚îÄ NUM_LAYERS (2)\n",
    "\n",
    "üìö WHAT EACH DIMENSION MEANS:\n",
    "\n",
    "1Ô∏è‚É£  NUM_LAYERS = 2\n",
    "   ‚Ä¢ You have a 2-layer RNN/LSTM\n",
    "   ‚Ä¢ Hidden state contains the final hidden vector from EACH layer\n",
    "   ‚Ä¢ Layer 0: First RNN layer's final hidden state\n",
    "   ‚Ä¢ Layer 1: Second RNN layer's final hidden state\n",
    "\n",
    "2Ô∏è‚É£  BATCH_SIZE = 16\n",
    "   ‚Ä¢ You're processing 16 sequences simultaneously\n",
    "   ‚Ä¢ Each sequence has its own hidden state\n",
    "   ‚Ä¢ Enables parallel processing\n",
    "\n",
    "3Ô∏è‚É£  HIDDEN_SIZE = 256\n",
    "   ‚Ä¢ Each hidden state vector has 256 dimensions\n",
    "   ‚Ä¢ This is the internal memory capacity of each RNN cell\n",
    "   ‚Ä¢ Stores the \"compressed\" information from the sequence\n",
    "\n",
    "üîÑ HIDDEN STATE EVOLUTION:\n",
    "\n",
    "At each timestep, the RNN updates its hidden state:\n",
    "\"\"\")\n",
    "\n",
    "# Demonstrate hidden state evolution\n",
    "print(\"TIMESTEP-BY-TIMESTEP HIDDEN STATE EVOLUTION:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Manual step-by-step processing to show hidden evolution\n",
    "h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "print(f\"Initial hidden state: {h0.shape}\")\n",
    "print(f\"  ‚îî‚îÄ All zeros: [num_layers={num_layers}, batch_size={batch_size}, hidden_size={hidden_size}]\")\n",
    "\n",
    "# Process each timestep manually\n",
    "for t in range(sequence_length):\n",
    "    input_t = embedded[:, t:t+1, :]  # Single timestep\n",
    "    output_t, h0 = rnn(input_t, h0)\n",
    "    print(f\"\\nTimestep {t+1}:\")\n",
    "    print(f\"  Input shape: {input_t.shape}\")\n",
    "    print(f\"  Output shape: {output_t.shape}\")\n",
    "    print(f\"  Hidden shape: {h0.shape}\")\n",
    "    print(f\"  ‚îî‚îÄ Hidden state updated for all {batch_size} sequences\")\n",
    "\n",
    "print(f\"\\nüéØ FINAL HIDDEN STATE:\")\n",
    "print(f\"Shape: {h0.shape}\")\n",
    "print(f\"Contains the 'final memory' of each sequence after processing all {sequence_length} timesteps\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: OUTPUT vs HIDDEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä OUTPUT TENSOR: {output.shape}\n",
    "   ‚Ä¢ Contains RNN output at EVERY timestep\n",
    "   ‚Ä¢ Shape: [batch_size, sequence_length, hidden_size]\n",
    "   ‚Ä¢ Use for: Many-to-many tasks (your case)\n",
    "\n",
    "üß† HIDDEN TENSOR: {hidden.shape}\n",
    "   ‚Ä¢ Contains FINAL hidden state from each layer\n",
    "   ‚Ä¢ Shape: [num_layers, batch_size, hidden_size]  \n",
    "   ‚Ä¢ Use for: Many-to-one tasks, or as input to next sequence\n",
    "\n",
    "üîç ACCESSING HIDDEN STATES:\n",
    "\"\"\")\n",
    "\n",
    "# Show how to access different parts of hidden state\n",
    "print(\"# Access final hidden state from last layer:\")\n",
    "final_layer_hidden = hidden[-1]  # Shape: [batch_size, hidden_size]\n",
    "print(f\"hidden[-1].shape = {final_layer_hidden.shape}\")\n",
    "\n",
    "print(\"\\n# Access hidden state from first layer:\")\n",
    "first_layer_hidden = hidden[0]  # Shape: [batch_size, hidden_size]\n",
    "print(f\"hidden[0].shape = {first_layer_hidden.shape}\")\n",
    "\n",
    "print(\"\\n# Access hidden state for specific batch item:\")\n",
    "batch_item_0_all_layers = hidden[:, 0, :]  # Shape: [num_layers, hidden_size]\n",
    "print(f\"hidden[:, 0, :].shape = {batch_item_0_all_layers.shape}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"LSTM vs RNN HIDDEN STATES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show difference between LSTM and RNN\n",
    "lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "lstm_output, (lstm_hidden, lstm_cell) = lstm(embedded)\n",
    "\n",
    "print(f\"\"\"\n",
    "üîÑ RNN HIDDEN STATE:\n",
    "   ‚Ä¢ Returns: hidden\n",
    "   ‚Ä¢ Shape: {hidden.shape}\n",
    "   ‚Ä¢ Contains: Final hidden state from each layer\n",
    "\n",
    "üß† LSTM HIDDEN STATE:\n",
    "   ‚Ä¢ Returns: (hidden, cell)\n",
    "   ‚Ä¢ Hidden shape: {lstm_hidden.shape}\n",
    "   ‚Ä¢ Cell shape: {lstm_cell.shape}\n",
    "   ‚Ä¢ Contains: Both hidden state AND cell state (LSTM's memory)\n",
    "\n",
    "üí° KEY INSIGHT:\n",
    "   LSTM returns TWO states because it has:\n",
    "   1. Hidden state (h) - what it outputs\n",
    "   2. Cell state (c) - internal memory\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"PRACTICAL USAGE EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ WHEN TO USE HIDDEN STATE:\n",
    "\n",
    "1Ô∏è‚É£  MANY-TO-ONE TASKS:\n",
    "   classifier = nn.Linear(hidden_size, num_classes)\n",
    "   prediction = classifier(hidden[-1])  # Use final layer's hidden state\n",
    "\n",
    "2Ô∏è‚É£  SEQUENCE CONTINUATION:\n",
    "   # Use final hidden state as initial state for next sequence\n",
    "   next_output, next_hidden = rnn(next_input, hidden)\n",
    "\n",
    "3Ô∏è‚É£  ENCODER-DECODER:\n",
    "   # Hidden state from encoder becomes initial state for decoder\n",
    "   decoder_output, _ = decoder_rnn(decoder_input, encoder_hidden)\n",
    "\n",
    "4Ô∏è‚É£  ATTENTION MECHANISMS:\n",
    "   # Use hidden states from all layers for attention computation\n",
    "   attention_weights = attention_layer(hidden)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ COMPLETE RNN/LSTM DATA FLOW GUIDE - FROM BEGINNER TO PRO\n",
      "================================================================================\n",
      "\n",
      "üî• PART 1: CLEARING UP THE MISCONCEPTION\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚ùå WRONG UNDERSTANDING (what you thought):\n",
      "   Layer 1 gets: seq_len[0] (first timestep)\n",
      "   Layer 2 gets: seq_len[1] (second timestep) + hidden from layer 1\n",
      "   Layer 3 gets: seq_len[2] (third timestep) + hidden from layer 2\n",
      "   \n",
      "‚úÖ CORRECT UNDERSTANDING:\n",
      "   ALL layers process ALL timesteps!\n",
      "   \n",
      "   Time flows HORIZONTALLY (across timesteps)\n",
      "   Layers stack VERTICALLY (depth-wise)\n",
      "   \n",
      "   Think of it like this:\n",
      "   - TIME dimension: seq_len (horizontal flow)\n",
      "   - LAYER dimension: num_layers (vertical stacking)\n",
      "\n",
      "\n",
      "üéØ PART 2: SINGLE LAYER RNN - HOW TIME FLOWS\n",
      "------------------------------------------------------------\n",
      "Input shape: torch.Size([2, 5, 3]) = [batch_size=2, seq_len=5, input_size=3]\n",
      "\n",
      "üîÑ MANUAL TIMESTEP-BY-TIMESTEP PROCESSING:\n",
      "==================================================\n",
      "Initial hidden state: torch.Size([1, 2, 4]) = [num_layers=1, batch_size=2, hidden_size=4]\n",
      "\n",
      "Timestep 0:\n",
      "  Input: torch.Size([2, 1, 3]) - x[:, 0, :] (all batches, timestep 0)\n",
      "  Output: torch.Size([2, 1, 4])\n",
      "  Hidden: torch.Size([1, 2, 4]) (updated for next timestep)\n",
      "  Hidden[0,0,:3]: [0.6825182  0.43369856 0.33444837]\n",
      "\n",
      "Timestep 1:\n",
      "  Input: torch.Size([2, 1, 3]) - x[:, 1, :] (all batches, timestep 1)\n",
      "  Output: torch.Size([2, 1, 4])\n",
      "  Hidden: torch.Size([1, 2, 4]) (updated for next timestep)\n",
      "  Hidden[0,0,:3]: [0.1834344  0.6883885  0.35154048]\n",
      "\n",
      "Timestep 2:\n",
      "  Input: torch.Size([2, 1, 3]) - x[:, 2, :] (all batches, timestep 2)\n",
      "  Output: torch.Size([2, 1, 4])\n",
      "  Hidden: torch.Size([1, 2, 4]) (updated for next timestep)\n",
      "  Hidden[0,0,:3]: [ 0.73848087  0.8688072  -0.14003779]\n",
      "\n",
      "Timestep 3:\n",
      "  Input: torch.Size([2, 1, 3]) - x[:, 3, :] (all batches, timestep 3)\n",
      "  Output: torch.Size([2, 1, 4])\n",
      "  Hidden: torch.Size([1, 2, 4]) (updated for next timestep)\n",
      "  Hidden[0,0,:3]: [0.79694283 0.8599584  0.0931404 ]\n",
      "\n",
      "Timestep 4:\n",
      "  Input: torch.Size([2, 1, 3]) - x[:, 4, :] (all batches, timestep 4)\n",
      "  Output: torch.Size([2, 1, 4])\n",
      "  Hidden: torch.Size([1, 2, 4]) (updated for next timestep)\n",
      "  Hidden[0,0,:3]: [ 0.8207473   0.8786785  -0.00674092]\n",
      "\n",
      "Manual processing result: torch.Size([2, 5, 4])\n",
      "Automatic processing result: torch.Size([2, 5, 4])\n",
      "Results match: True\n",
      "\n",
      "\n",
      "üèóÔ∏è PART 3: MULTI-LAYER RNN - VERTICAL STACKING\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß† KEY INSIGHT: Multi-layer RNN Architecture\n",
      "\n",
      "Layer 2  [h2_0] ‚Üí [h2_1] ‚Üí [h2_2] ‚Üí [h2_3] ‚Üí [h2_4]  (Final outputs)\n",
      "           ‚Üë        ‚Üë        ‚Üë        ‚Üë        ‚Üë\n",
      "Layer 1  [h1_0] ‚Üí [h1_1] ‚Üí [h1_2] ‚Üí [h1_3] ‚Üí [h1_4]\n",
      "           ‚Üë        ‚Üë        ‚Üë        ‚Üë        ‚Üë  \n",
      "Layer 0  [h0_0] ‚Üí [h0_1] ‚Üí [h0_2] ‚Üí [h0_3] ‚Üí [h0_4]\n",
      "           ‚Üë        ‚Üë        ‚Üë        ‚Üë        ‚Üë\n",
      "Input     x_0      x_1      x_2      x_3      x_4\n",
      "\n",
      "- Horizontal arrows (‚Üí): Time flow within each layer\n",
      "- Vertical arrows (‚Üë): Data flow between layers at same timestep\n",
      "\n",
      "\n",
      "Multi-layer RNN:\n",
      "  Input: torch.Size([2, 5, 3])\n",
      "  Output: torch.Size([2, 5, 4]) (same as single layer!)\n",
      "  Hidden: torch.Size([3, 2, 4]) = [num_layers=3, batch_size=2, hidden_size=4]\n",
      "\n",
      "üîç LAYER-BY-LAYER BREAKDOWN:\n",
      "  Layer 0 final hidden: torch.Size([2, 4])\n",
      "    Sample values: [-0.35523608  0.5167532  -0.04714062]\n",
      "  Layer 1 final hidden: torch.Size([2, 4])\n",
      "    Sample values: [ 0.18950969 -0.1408389  -0.08799697]\n",
      "  Layer 2 final hidden: torch.Size([2, 4])\n",
      "    Sample values: [ 0.17303309 -0.03049456 -0.27265048]\n",
      "\n",
      "\n",
      "üîß PART 4: MANUAL MULTI-LAYER IMPLEMENTATION\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß™ TESTING MANUAL IMPLEMENTATION:\n",
      "Processing timestep by timestep:\n",
      "\n",
      "‚è∞ TIMESTEP 0:\n",
      "  Input to layer 0: torch.Size([2, 1, 3])\n",
      "  Layer 0:\n",
      "    Input:  torch.Size([2, 1, 3])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 1:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 2:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "\n",
      "‚è∞ TIMESTEP 1:\n",
      "  Input to layer 0: torch.Size([2, 1, 3])\n",
      "  Layer 0:\n",
      "    Input:  torch.Size([2, 1, 3])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 1:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 2:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "\n",
      "‚è∞ TIMESTEP 2:\n",
      "  Input to layer 0: torch.Size([2, 1, 3])\n",
      "  Layer 0:\n",
      "    Input:  torch.Size([2, 1, 3])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 1:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 2:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "\n",
      "‚è∞ TIMESTEP 3:\n",
      "  Input to layer 0: torch.Size([2, 1, 3])\n",
      "  Layer 0:\n",
      "    Input:  torch.Size([2, 1, 3])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 1:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 2:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "\n",
      "‚è∞ TIMESTEP 4:\n",
      "  Input to layer 0: torch.Size([2, 1, 3])\n",
      "  Layer 0:\n",
      "    Input:  torch.Size([2, 1, 3])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 1:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "  Layer 2:\n",
      "    Input:  torch.Size([2, 1, 4])\n",
      "    Output: torch.Size([2, 1, 4])\n",
      "    Hidden: torch.Size([1, 2, 4])\n",
      "Manual output shape: torch.Size([2, 5, 4])\n",
      "Manual hidden shape: torch.Size([3, 2, 4])\n",
      "\n",
      "\n",
      "üß† PART 5: LSTM - SAME FLOW, MORE MEMORY\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîÑ LSTM vs RNN - SAME TIME/LAYER FLOW!\n",
      "\n",
      "The flow is IDENTICAL to RNN:\n",
      "- Time flows horizontally across timesteps\n",
      "- Layers stack vertically\n",
      "- Each layer processes ALL timesteps\n",
      "\n",
      "The only difference:\n",
      "- RNN: Returns hidden state only\n",
      "- LSTM: Returns (hidden state, cell state)\n",
      "\n",
      "LSTM shapes:\n",
      "  Output: torch.Size([2, 5, 4]) (same as RNN!)\n",
      "  Hidden: torch.Size([3, 2, 4]) (same as RNN!)\n",
      "  Cell:   torch.Size([3, 2, 4]) (additional memory!)\n",
      "\n",
      "\n",
      "\n",
      "üìä PART 6: VISUAL DEMONSTRATION\n",
      "------------------------------------------------------------\n",
      "Demo input shape: torch.Size([1, 4, 2])\n",
      "Demo input values:\n",
      "  Timestep 0: [1.0, 0.0]\n",
      "  Timestep 1: [0.0, 1.0]\n",
      "  Timestep 2: [1.0, 1.0]\n",
      "  Timestep 3: [0.0, 0.0]\n",
      "\n",
      "üîç DETAILED FLOW ANALYSIS:\n",
      "\n",
      "Initial hidden states:\n",
      "  Layer 0: [0.0, 0.0, 0.0]\n",
      "  Layer 1: [0.0, 0.0, 0.0]\n",
      "\n",
      "üìç TIMESTEP 0 - Input: [1.0, 0.0]\n",
      "  ----------------------------------------\n",
      "  After processing:\n",
      "    Layer 0 hidden: [0.25704988837242126, -0.49125993251800537]... (showing first 2 values)\n",
      "    Layer 1 hidden: [0.0, 0.0]... (showing first 2 values)\n",
      "    Output: [0.5385422110557556, 0.10243161767721176]... (showing first 2 values)\n",
      "\n",
      "üìç TIMESTEP 1 - Input: [0.0, 1.0]\n",
      "  ----------------------------------------\n",
      "  After processing:\n",
      "    Layer 0 hidden: [0.09623092412948608, -0.7296839356422424]... (showing first 2 values)\n",
      "    Layer 1 hidden: [0.0, 0.0]... (showing first 2 values)\n",
      "    Output: [0.46831268072128296, 0.08392702788114548]... (showing first 2 values)\n",
      "\n",
      "üìç TIMESTEP 2 - Input: [1.0, 1.0]\n",
      "  ----------------------------------------\n",
      "  After processing:\n",
      "    Layer 0 hidden: [-0.000404804915888235, -0.7892251014709473]... (showing first 2 values)\n",
      "    Layer 1 hidden: [0.0, 0.0]... (showing first 2 values)\n",
      "    Output: [0.4489246904850006, 0.07524237036705017]... (showing first 2 values)\n",
      "\n",
      "üìç TIMESTEP 3 - Input: [0.0, 0.0]\n",
      "  ----------------------------------------\n",
      "  After processing:\n",
      "    Layer 0 hidden: [0.2204161435365677, -0.5813832879066467]... (showing first 2 values)\n",
      "    Layer 1 hidden: [0.0, 0.0]... (showing first 2 values)\n",
      "    Output: [0.4209286868572235, 0.21364957094192505]... (showing first 2 values)\n",
      "\n",
      "\n",
      "‚ö†Ô∏è PART 7: COMMON MISTAKES & CLARIFICATIONS\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚ùå MISTAKE 1: \"Each layer processes different timesteps\"\n",
      "‚úÖ CORRECT: Each layer processes ALL timesteps\n",
      "\n",
      "‚ùå MISTAKE 2: \"num_layers means number of timesteps\"\n",
      "‚úÖ CORRECT: num_layers means depth (vertical stacking)\n",
      "\n",
      "‚ùå MISTAKE 3: \"seq_len and num_layers should match\"\n",
      "‚úÖ CORRECT: They are independent! seq_len=time, num_layers=depth\n",
      "\n",
      "‚ùå MISTAKE 4: \"Data flows: layer1‚Üílayer2‚Üílayer3 for each timestep\"\n",
      "‚úÖ CORRECT: At each timestep t, data flows:\n",
      "           input_t ‚Üí layer1 ‚Üí layer2 ‚Üí layer3 ‚Üí output_t\n",
      "\n",
      "üéØ KEY INSIGHTS:\n",
      "\n",
      "1. TIME DIMENSION (seq_len):\n",
      "   - How many timesteps in your sequence\n",
      "   - RNN processes t=0, then t=1, then t=2, etc.\n",
      "   - Each timestep sees the previous hidden state\n",
      "\n",
      "2. LAYER DIMENSION (num_layers):\n",
      "   - How deep your network is\n",
      "   - More layers = more representational power\n",
      "   - Each layer adds complexity to the transformation\n",
      "\n",
      "3. BATCH DIMENSION:\n",
      "   - How many sequences you process in parallel\n",
      "   - Each sequence has its own hidden state\n",
      "   - Enables efficient GPU computation\n",
      "\n",
      "üîÑ THE COMPLETE FLOW:\n",
      "   For each timestep t:\n",
      "     1. Take input[t] and previous_hidden\n",
      "     2. Pass through Layer 0 ‚Üí get new_hidden[0]\n",
      "     3. Pass Layer 0 output through Layer 1 ‚Üí get new_hidden[1]\n",
      "     4. Continue for all layers\n",
      "     5. Final layer output becomes output[t]\n",
      "     6. Move to next timestep with updated hidden states\n",
      "\n",
      "\n",
      "\n",
      "üí° PART 8: PRACTICAL EXAMPLES\n",
      "------------------------------------------------------------\n",
      "\n",
      "üéØ REAL-WORLD SCENARIOS:\n",
      "\n",
      "üìù EXAMPLE 1: Sentiment Analysis\n",
      "   Input: \"I love this movie!\" ‚Üí [1, 5, 9, 3] (token IDs)\n",
      "   seq_len = 4 (4 words)\n",
      "   num_layers = 2 (2-layer LSTM for complexity)\n",
      "   \n",
      "   Flow: Each word flows through both layers at each timestep\n",
      "   \n",
      "üìà EXAMPLE 2: Stock Price Prediction  \n",
      "   Input: Last 30 days of prices ‚Üí [100, 101, 99, 102, ...] \n",
      "   seq_len = 30 (30 days)\n",
      "   num_layers = 3 (3 layers to capture complex patterns)\n",
      "   \n",
      "   Flow: Each day's price flows through all 3 layers\n",
      "\n",
      "üéµ EXAMPLE 3: Music Generation\n",
      "   Input: Musical notes ‚Üí [C, D, E, F, G]\n",
      "   seq_len = 5 (5 notes)  \n",
      "   num_layers = 4 (deep network for creativity)\n",
      "   \n",
      "   Flow: Each note flows through all 4 layers sequentially\n",
      "\n",
      "üîë REMEMBER: \n",
      "   - seq_len = length of your sequence (time)\n",
      "   - num_layers = depth of your network (complexity)\n",
      "   - They work together, not against each other!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéâ CONGRATULATIONS! YOU NOW UNDERSTAND RNN/LSTM FLOW LIKE A PRO!\n",
      "================================================================================\n",
      "\n",
      "üìö SUMMARY OF KEY CONCEPTS:\n",
      "\n",
      "1Ô∏è‚É£  TIME flows HORIZONTALLY (across timesteps)\n",
      "2Ô∏è‚É£  LAYERS stack VERTICALLY (for depth/complexity)\n",
      "3Ô∏è‚É£  ALL layers process ALL timesteps\n",
      "4Ô∏è‚É£  Hidden state carries information through time\n",
      "5Ô∏è‚É£  seq_len and num_layers are independent dimensions\n",
      "6Ô∏è‚É£  LSTM = RNN + extra memory (cell state)\n",
      "\n",
      "üöÄ YOU'RE NOW READY TO:\n",
      "   ‚úÖ Design RNN/LSTM architectures confidently\n",
      "   ‚úÖ Debug shape mismatches like a pro\n",
      "   ‚úÖ Understand exactly how your data flows\n",
      "   ‚úÖ Choose appropriate seq_len and num_layers\n",
      "   ‚úÖ Implement custom RNN solutions\n",
      "\n",
      "Happy deep learning! ü§ñ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ COMPLETE RNN/LSTM DATA FLOW GUIDE - FROM BEGINNER TO PRO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: THE BIG MISCONCEPTION - CLEARING IT UP FIRST!\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"üî• PART 1: CLEARING UP THE MISCONCEPTION\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "‚ùå WRONG UNDERSTANDING (what you thought):\n",
    "   Layer 1 gets: seq_len[0] (first timestep)\n",
    "   Layer 2 gets: seq_len[1] (second timestep) + hidden from layer 1\n",
    "   Layer 3 gets: seq_len[2] (third timestep) + hidden from layer 2\n",
    "   \n",
    "‚úÖ CORRECT UNDERSTANDING:\n",
    "   ALL layers process ALL timesteps!\n",
    "   \n",
    "   Time flows HORIZONTALLY (across timesteps)\n",
    "   Layers stack VERTICALLY (depth-wise)\n",
    "   \n",
    "   Think of it like this:\n",
    "   - TIME dimension: seq_len (horizontal flow)\n",
    "   - LAYER dimension: num_layers (vertical stacking)\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: SINGLE LAYER RNN - UNDERSTANDING TIME FLOW\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"üéØ PART 2: SINGLE LAYER RNN - HOW TIME FLOWS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create a simple single-layer RNN\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "\n",
    "single_rnn = nn.RNN(input_size, hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "# Create sample data\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "print(f\"Input shape: {x.shape} = [batch_size={batch_size}, seq_len={seq_len}, input_size={input_size}]\")\n",
    "\n",
    "print(f\"\\nüîÑ MANUAL TIMESTEP-BY-TIMESTEP PROCESSING:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize hidden state\n",
    "hidden = torch.zeros(1, batch_size, hidden_size)\n",
    "print(f\"Initial hidden state: {hidden.shape} = [num_layers=1, batch_size={batch_size}, hidden_size={hidden_size}]\")\n",
    "\n",
    "# Process each timestep manually\n",
    "outputs_manual = []\n",
    "for t in range(seq_len):\n",
    "    # Get input for this timestep\n",
    "    input_t = x[:, t:t+1, :]  # Shape: [batch_size, 1, input_size]\n",
    "    \n",
    "    # Process through RNN\n",
    "    output_t, hidden = single_rnn(input_t, hidden)\n",
    "    outputs_manual.append(output_t)\n",
    "    \n",
    "    print(f\"\\nTimestep {t}:\")\n",
    "    print(f\"  Input: {input_t.shape} - x[:, {t}, :] (all batches, timestep {t})\")\n",
    "    print(f\"  Output: {output_t.shape}\")\n",
    "    print(f\"  Hidden: {hidden.shape} (updated for next timestep)\")\n",
    "    print(f\"  Hidden[0,0,:3]: {hidden[0,0,:3].detach().numpy()}\")  # Show first 3 values\n",
    "\n",
    "# Concatenate all outputs\n",
    "manual_output = torch.cat(outputs_manual, dim=1)\n",
    "print(f\"\\nManual processing result: {manual_output.shape}\")\n",
    "\n",
    "# Compare with automatic processing\n",
    "auto_output, auto_hidden = single_rnn(x)\n",
    "print(f\"Automatic processing result: {auto_output.shape}\")\n",
    "print(f\"Results match: {torch.allclose(manual_output, auto_output, atol=1e-6)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: MULTI-LAYER RNN - VERTICAL STACKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"üèóÔ∏è PART 3: MULTI-LAYER RNN - VERTICAL STACKING\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "num_layers = 3\n",
    "multi_rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "print(f\"\"\"\n",
    "üß† KEY INSIGHT: Multi-layer RNN Architecture\n",
    "\n",
    "Layer 2  [h2_0] ‚Üí [h2_1] ‚Üí [h2_2] ‚Üí [h2_3] ‚Üí [h2_4]  (Final outputs)\n",
    "           ‚Üë        ‚Üë        ‚Üë        ‚Üë        ‚Üë\n",
    "Layer 1  [h1_0] ‚Üí [h1_1] ‚Üí [h1_2] ‚Üí [h1_3] ‚Üí [h1_4]\n",
    "           ‚Üë        ‚Üë        ‚Üë        ‚Üë        ‚Üë  \n",
    "Layer 0  [h0_0] ‚Üí [h0_1] ‚Üí [h0_2] ‚Üí [h0_3] ‚Üí [h0_4]\n",
    "           ‚Üë        ‚Üë        ‚Üë        ‚Üë        ‚Üë\n",
    "Input     x_0      x_1      x_2      x_3      x_4\n",
    "\n",
    "- Horizontal arrows (‚Üí): Time flow within each layer\n",
    "- Vertical arrows (‚Üë): Data flow between layers at same timestep\n",
    "\"\"\")\n",
    "\n",
    "# Process with multi-layer RNN\n",
    "multi_output, multi_hidden = multi_rnn(x)\n",
    "print(f\"\\nMulti-layer RNN:\")\n",
    "print(f\"  Input: {x.shape}\")\n",
    "print(f\"  Output: {multi_output.shape} (same as single layer!)\")\n",
    "print(f\"  Hidden: {multi_hidden.shape} = [num_layers={num_layers}, batch_size={batch_size}, hidden_size={hidden_size}]\")\n",
    "\n",
    "print(f\"\\nüîç LAYER-BY-LAYER BREAKDOWN:\")\n",
    "for layer in range(num_layers):\n",
    "    print(f\"  Layer {layer} final hidden: {multi_hidden[layer].shape}\")\n",
    "    print(f\"    Sample values: {multi_hidden[layer][0, :3].detach().numpy()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: MANUAL MULTI-LAYER IMPLEMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"üîß PART 4: MANUAL MULTI-LAYER IMPLEMENTATION\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def manual_multilayer_rnn(x, num_layers, hidden_size):\n",
    "    \"\"\"Manual implementation to show exactly how layers work\"\"\"\n",
    "    batch_size, seq_len, input_size = x.shape\n",
    "    \n",
    "    # Create individual RNN cells for each layer\n",
    "    rnn_layers = []\n",
    "    for i in range(num_layers):\n",
    "        layer_input_size = input_size if i == 0 else hidden_size\n",
    "        rnn_layers.append(nn.RNN(layer_input_size, hidden_size, num_layers=1, batch_first=True))\n",
    "    \n",
    "    # Initialize hidden states for all layers\n",
    "    hidden_states = [torch.zeros(1, batch_size, hidden_size) for _ in range(num_layers)]\n",
    "    \n",
    "    # Store outputs for each timestep\n",
    "    all_outputs = []\n",
    "    \n",
    "    print(\"Processing timestep by timestep:\")\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        print(f\"\\n‚è∞ TIMESTEP {t}:\")\n",
    "        \n",
    "        # Start with input for this timestep\n",
    "        layer_input = x[:, t:t+1, :]  # [batch_size, 1, input_size]\n",
    "        print(f\"  Input to layer 0: {layer_input.shape}\")\n",
    "        \n",
    "        # Pass through each layer\n",
    "        for layer_idx in range(num_layers):\n",
    "            layer_output, hidden_states[layer_idx] = rnn_layers[layer_idx](\n",
    "                layer_input, hidden_states[layer_idx]\n",
    "            )\n",
    "            \n",
    "            print(f\"  Layer {layer_idx}:\")\n",
    "            print(f\"    Input:  {layer_input.shape}\")\n",
    "            print(f\"    Output: {layer_output.shape}\")\n",
    "            print(f\"    Hidden: {hidden_states[layer_idx].shape}\")\n",
    "            \n",
    "            # Output of this layer becomes input to next layer\n",
    "            layer_input = layer_output\n",
    "        \n",
    "        # The final layer's output is what we keep\n",
    "        all_outputs.append(layer_output)\n",
    "    \n",
    "    # Combine all timestep outputs\n",
    "    final_output = torch.cat(all_outputs, dim=1)\n",
    "    final_hidden = torch.cat(hidden_states, dim=0)\n",
    "    \n",
    "    return final_output, final_hidden\n",
    "\n",
    "# Test manual implementation\n",
    "print(f\"\\nüß™ TESTING MANUAL IMPLEMENTATION:\")\n",
    "manual_out, manual_hid = manual_multilayer_rnn(x, num_layers, hidden_size)\n",
    "print(f\"Manual output shape: {manual_out.shape}\")\n",
    "print(f\"Manual hidden shape: {manual_hid.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: LSTM DIFFERENCES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"üß† PART 5: LSTM - SAME FLOW, MORE MEMORY\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "lstm_output, (lstm_hidden, lstm_cell) = lstm(x)\n",
    "\n",
    "print(f\"\"\"\n",
    "üîÑ LSTM vs RNN - SAME TIME/LAYER FLOW!\n",
    "\n",
    "The flow is IDENTICAL to RNN:\n",
    "- Time flows horizontally across timesteps\n",
    "- Layers stack vertically\n",
    "- Each layer processes ALL timesteps\n",
    "\n",
    "The only difference:\n",
    "- RNN: Returns hidden state only\n",
    "- LSTM: Returns (hidden state, cell state)\n",
    "\n",
    "LSTM shapes:\n",
    "  Output: {lstm_output.shape} (same as RNN!)\n",
    "  Hidden: {lstm_hidden.shape} (same as RNN!)\n",
    "  Cell:   {lstm_cell.shape} (additional memory!)\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: VISUAL DEMONSTRATION WITH REAL EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"üìä PART 6: VISUAL DEMONSTRATION\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create a more interpretable example\n",
    "batch_size = 1  # Single sequence for clarity\n",
    "seq_len = 4\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "num_layers = 2\n",
    "\n",
    "# Create interpretable input data\n",
    "x_demo = torch.tensor([[[1.0, 0.0],  # timestep 0: [1, 0]\n",
    "                        [0.0, 1.0],  # timestep 1: [0, 1] \n",
    "                        [1.0, 1.0],  # timestep 2: [1, 1]\n",
    "                        [0.0, 0.0]   # timestep 3: [0, 0]\n",
    "                       ]], dtype=torch.float32)\n",
    "\n",
    "print(f\"Demo input shape: {x_demo.shape}\")\n",
    "print(f\"Demo input values:\")\n",
    "for t in range(seq_len):\n",
    "    print(f\"  Timestep {t}: {x_demo[0, t].tolist()}\")\n",
    "\n",
    "# Create demo RNN\n",
    "demo_rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "# Process and show detailed flow\n",
    "print(f\"\\nüîç DETAILED FLOW ANALYSIS:\")\n",
    "\n",
    "# Get layer weights to understand what's happening\n",
    "with torch.no_grad():\n",
    "    # Initialize hidden states\n",
    "    h = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "    \n",
    "    print(f\"\\nInitial hidden states:\")\n",
    "    for layer in range(num_layers):\n",
    "        print(f\"  Layer {layer}: {h[layer].squeeze().tolist()}\")\n",
    "    \n",
    "    # Manual processing with detailed output\n",
    "    for t in range(seq_len):\n",
    "        input_t = x_demo[:, t:t+1, :]\n",
    "        \n",
    "        print(f\"\\nüìç TIMESTEP {t} - Input: {input_t.squeeze().tolist()}\")\n",
    "        print(\"  \" + \"-\" * 40)\n",
    "        \n",
    "        # Layer 0\n",
    "        layer_0_out, h_new_0 = demo_rnn(input_t, h)\n",
    "        h[0] = h_new_0[0]  # Update layer 0 hidden state\n",
    "        \n",
    "        # For demonstration, let's track what each layer would do\n",
    "        # (This is simplified - actual PyTorch does this internally)\n",
    "        \n",
    "        print(f\"  After processing:\")\n",
    "        print(f\"    Layer 0 hidden: {h[0].squeeze()[:2].tolist()}... (showing first 2 values)\")\n",
    "        print(f\"    Layer 1 hidden: {h[1].squeeze()[:2].tolist()}... (showing first 2 values)\")\n",
    "        print(f\"    Output: {layer_0_out.squeeze()[:2].tolist()}... (showing first 2 values)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: COMMON MISTAKES AND CLARIFICATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"‚ö†Ô∏è PART 7: COMMON MISTAKES & CLARIFICATIONS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "‚ùå MISTAKE 1: \"Each layer processes different timesteps\"\n",
    "‚úÖ CORRECT: Each layer processes ALL timesteps\n",
    "\n",
    "‚ùå MISTAKE 2: \"num_layers means number of timesteps\"\n",
    "‚úÖ CORRECT: num_layers means depth (vertical stacking)\n",
    "\n",
    "‚ùå MISTAKE 3: \"seq_len and num_layers should match\"\n",
    "‚úÖ CORRECT: They are independent! seq_len=time, num_layers=depth\n",
    "\n",
    "‚ùå MISTAKE 4: \"Data flows: layer1‚Üílayer2‚Üílayer3 for each timestep\"\n",
    "‚úÖ CORRECT: At each timestep t, data flows:\n",
    "           input_t ‚Üí layer1 ‚Üí layer2 ‚Üí layer3 ‚Üí output_t\n",
    "\n",
    "üéØ KEY INSIGHTS:\n",
    "\n",
    "1. TIME DIMENSION (seq_len):\n",
    "   - How many timesteps in your sequence\n",
    "   - RNN processes t=0, then t=1, then t=2, etc.\n",
    "   - Each timestep sees the previous hidden state\n",
    "\n",
    "2. LAYER DIMENSION (num_layers):\n",
    "   - How deep your network is\n",
    "   - More layers = more representational power\n",
    "   - Each layer adds complexity to the transformation\n",
    "\n",
    "3. BATCH DIMENSION:\n",
    "   - How many sequences you process in parallel\n",
    "   - Each sequence has its own hidden state\n",
    "   - Enables efficient GPU computation\n",
    "\n",
    "üîÑ THE COMPLETE FLOW:\n",
    "   For each timestep t:\n",
    "     1. Take input[t] and previous_hidden\n",
    "     2. Pass through Layer 0 ‚Üí get new_hidden[0]\n",
    "     3. Pass Layer 0 output through Layer 1 ‚Üí get new_hidden[1]\n",
    "     4. Continue for all layers\n",
    "     5. Final layer output becomes output[t]\n",
    "     6. Move to next timestep with updated hidden states\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 8: PRACTICAL EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"üí° PART 8: PRACTICAL EXAMPLES\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ REAL-WORLD SCENARIOS:\n",
    "\n",
    "üìù EXAMPLE 1: Sentiment Analysis\n",
    "   Input: \"I love this movie!\" ‚Üí [1, 5, 9, 3] (token IDs)\n",
    "   seq_len = 4 (4 words)\n",
    "   num_layers = 2 (2-layer LSTM for complexity)\n",
    "   \n",
    "   Flow: Each word flows through both layers at each timestep\n",
    "   \n",
    "üìà EXAMPLE 2: Stock Price Prediction  \n",
    "   Input: Last 30 days of prices ‚Üí [100, 101, 99, 102, ...] \n",
    "   seq_len = 30 (30 days)\n",
    "   num_layers = 3 (3 layers to capture complex patterns)\n",
    "   \n",
    "   Flow: Each day's price flows through all 3 layers\n",
    "\n",
    "üéµ EXAMPLE 3: Music Generation\n",
    "   Input: Musical notes ‚Üí [C, D, E, F, G]\n",
    "   seq_len = 5 (5 notes)  \n",
    "   num_layers = 4 (deep network for creativity)\n",
    "   \n",
    "   Flow: Each note flows through all 4 layers sequentially\n",
    "\n",
    "üîë REMEMBER: \n",
    "   - seq_len = length of your sequence (time)\n",
    "   - num_layers = depth of your network (complexity)\n",
    "   - They work together, not against each other!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ CONGRATULATIONS! YOU NOW UNDERSTAND RNN/LSTM FLOW LIKE A PRO!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "üìö SUMMARY OF KEY CONCEPTS:\n",
    "\n",
    "1Ô∏è‚É£  TIME flows HORIZONTALLY (across timesteps)\n",
    "2Ô∏è‚É£  LAYERS stack VERTICALLY (for depth/complexity)\n",
    "3Ô∏è‚É£  ALL layers process ALL timesteps\n",
    "4Ô∏è‚É£  Hidden state carries information through time\n",
    "5Ô∏è‚É£  seq_len and num_layers are independent dimensions\n",
    "6Ô∏è‚É£  LSTM = RNN + extra memory (cell state)\n",
    "\n",
    "üöÄ YOU'RE NOW READY TO:\n",
    "   ‚úÖ Design RNN/LSTM architectures confidently\n",
    "   ‚úÖ Debug shape mismatches like a pro\n",
    "   ‚úÖ Understand exactly how your data flows\n",
    "   ‚úÖ Choose appropriate seq_len and num_layers\n",
    "   ‚úÖ Implement custom RNN solutions\n",
    "\n",
    "Happy deep learning! ü§ñ\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
